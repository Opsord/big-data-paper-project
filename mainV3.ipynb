{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2a9491",
   "metadata": {},
   "source": [
    "## Selección de dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3c74c3e",
   "metadata": {},
   "source": [
    "import pandas as pd  # Librería para manipulación y análisis de datos\n",
    "\n",
    "# Cargar los datasets\n",
    "df_only_trivial = pd.read_csv('datasets/OnlyTrivial_dt.csv') # Cargar el dataset de casos triviales\n",
    "df_only_non_trivial = pd.read_csv('datasets/OnlyNonTrivial_dt.csv') # Cargar el dataset de casos no triviales\n",
    "\n",
    "# Seleccionar el dataset y crear una copia explícita\n",
    "dataset = df_only_trivial.copy() # Seleccionar el dataset de casos triviales y crear una copia para manipularlo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81f2e3ec",
   "metadata": {},
   "source": "## Información de dataset"
  },
  {
   "cell_type": "code",
   "id": "efff255e",
   "metadata": {},
   "source": [
    "# Mostrar las primeras filas del dataset\n",
    "dataset.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f519e66e",
   "metadata": {},
   "source": [
    "# Mostrar la información del dataset\n",
    "dataset.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1635b75",
   "metadata": {},
   "source": [
    "# Descripción estadística del dataset\n",
    "dataset.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c137e1fd",
   "metadata": {},
   "source": [
    "# Histograma de las características principales\n",
    "principal_metrics = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "# Generar histograma\n",
    "dataset[principal_metrics].hist(bins=50, figsize=(20, 15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6f4b2b3",
   "metadata": {},
   "source": [
    "## Conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "id": "db540242",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el dataset en un conjunto de entrenamiento y uno de prueba\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mostrar la cantidad de datos en cada conjunto\n",
    "print(\"Largo de conjuntos: \")\n",
    "print(\"Entrenamiento: \", len(train_set))\n",
    "print(\"Prueba: \", len(test_set))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcdcfcf4",
   "metadata": {},
   "source": [
    "# Estabilización de los conjuntos de entrenamiento y prueba\n",
    "import numpy as np\n",
    "from zlib import crc32\n",
    "\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "# Como el dataset no tiene una columna de identificación, se creará \n",
    "# una columna con el índice de cada fila\n",
    "dataset_with_id = dataset.reset_index()\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "train_set, test_set = split_train_test_by_id(dataset_with_id, 0.2, \"index\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a5cbfc3",
   "metadata": {},
   "source": [
    "## Exploración"
   ]
  },
  {
   "cell_type": "code",
   "id": "525e224f",
   "metadata": {},
   "source": [
    "# Copia de dataset para manipulación\n",
    "exploration_dataset = train_set.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "928061dc",
   "metadata": {},
   "source": [
    "# Escalado de las características\n",
    "import seaborn as sns  # Librería para visualización de datos\n",
    "import matplotlib.pyplot as plt  # Importar matplotlib para visualización\n",
    "from sklearn.preprocessing import StandardScaler  # Escalador\n",
    "from sklearn.pipeline import Pipeline  # Pipeline para encadenar pasos\n",
    "\n",
    "# Seleccionar las columnas a escalar\n",
    "columns_to_scale = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "\n",
    "# Asegurar que las columnas sean de tipo float64\n",
    "exploration_dataset[columns_to_scale] = exploration_dataset[columns_to_scale].astype('float64')\n",
    "\n",
    "# Crear un pipeline para el escalado\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Aplicar el escalado a las columnas seleccionadas\n",
    "exploration_dataset[columns_to_scale] = pipeline.fit_transform(exploration_dataset[columns_to_scale])\n",
    "\n",
    "# Mapa de calor de correlaciones\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(dataset[columns_to_scale].corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2dfb8a1e90c6dbfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparación de datos",
   "id": "f3a57235d2425a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Limpieza de datos nulos mediante reemplazo por la mediana con SimpleImputer\n",
    "\n",
    "from sklearn.impute import SimpleImputer  # Importar SimpleImputer\n",
    "\n",
    "# Crear un SimpleImputer con la estrategia de reemplazo por la mediana\n",
    "# Se ocupa la mediana por ser más robusta a valores atípicos\n",
    "imputer = SimpleImputer(strategy='median') \n",
    "\n",
    "# Seleccionar las columnas numéricas\n",
    "numerical_columns = dataset.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Aplicar el imputer a las columnas numéricas\n",
    "imputer.fit(dataset[numerical_columns])\n",
    "\n",
    "# Transformar el dataset\n",
    "dataset[numerical_columns] = imputer.transform(dataset[numerical_columns])\n",
    "\n",
    "# Verificar si hay valores nulos\n",
    "dataset.isnull().sum()"
   ],
   "id": "8dcf87e435676aba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Paso de variables categóricas a numéricas Parte 1\n",
    "\n",
    "# Importar OrdinalEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# Seleccionar las columnas categóricas (Solo se debe ocupar la columna 'type')\n",
    "categorical_columns = ['type']\n",
    "\n",
    "# Crear un OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Aplicar el OrdinalEncoder a las columnas categóricas\n",
    "type_encoded = ordinal_encoder.fit_transform(dataset[categorical_columns])\n",
    "\n",
    "# Mostrar las categorías\n",
    "ordinal_encoder.categories_"
   ],
   "id": "67aee8587584d4a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Paso de variables categóricas a numéricas Parte 2\n",
    "\n",
    "# Importar OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Crear un OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "# Aplicar el OneHotEncoder a las columnas categóricas\n",
    "type_1hot = cat_encoder.fit_transform(dataset[categorical_columns])\n",
    "\n",
    "# Mostrar las categorías\n",
    "type_1hot.toarray()"
   ],
   "id": "a5202e93472c3097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformación de datos",
   "id": "f5fc7b42a93d8c4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Crear un pipeline para la transformación de datos\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definir pipeline para las columnas numéricas\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Seleccionar las columnas numéricas (metricas principales)\n",
    "numerical_columns = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "\n",
    "# Aplicar el pipeline a las columnas numéricas\n",
    "dataset_transformed = num_pipeline.fit_transform(dataset[numerical_columns])\n",
    "\n",
    "# Limpiar valores nulos\n",
    "#dataset_transformed = dataset.dropna(subset=numerical_columns)\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataset_transformed"
   ],
   "id": "9339df0a0e66e0ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combinar transformaciones\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Seleccionar las columnas categóricas\n",
    "categorical_columns = ['type']\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numerical_columns = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "\n",
    "# Crear un ColumnTransformer\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_columns),\n",
    "    ('cat', OneHotEncoder(), categorical_columns)\n",
    "])\n",
    "\n",
    "# Aplicar el ColumnTransformer al dataset\n",
    "dataset_prepared = full_pipeline.fit_transform(dataset)\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataset_prepared"
   ],
   "id": "ec4f98d9bbe87dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento y evaluación de modelos en el conjunto de entrenamiento",
   "id": "97b4264c3e7d0c71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regresión Lineal",
   "id": "79b9ce0fcaf2178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entrenamiento y evaluación de modelos en el conjunto de entrenamiento\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  # Importar modelo de regresión lineal\n",
    "from sklearn.metrics import mean_squared_error # Importar métrica de error cuadrático medio\n",
    "\n",
    "# Seleccionar el modelo\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "lin_reg.fit(dataset_prepared, dataset['refactoring'])\n",
    "\n",
    "# Predecir en todo el conjunto de entrenamiento\n",
    "dataset_predictions = lin_reg.predict(dataset_prepared)\n",
    "\n",
    "# Calcular el error\n",
    "lin_mse = mean_squared_error(dataset['refactoring'], dataset_predictions)\n",
    "lin_reg_mse = np.sqrt(lin_mse)\n",
    "print(\"Error cuadrático medio: \", lin_reg_mse)\n",
    "# Raíz del error cuadrático medio\n",
    "rmse = np.sqrt(lin_reg_mse)\n",
    "print(\"Raíz del error cuadrático medio: \", rmse)"
   ],
   "id": "77c6ef547dc3ef8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree Regressor",
   "id": "205b37093f3732bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entrenamiento y evaluación de modelos en el conjunto de entrenamiento\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor  # Importar modelo de árbol de decisión\n",
    "\n",
    "# Seleccionar el modelo\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "# Entrenar el modelo\n",
    "tree_reg.fit(dataset_prepared, dataset['refactoring'])\n",
    "\n",
    "# Predecir en todo el conjunto de entrenamiento\n",
    "dataset_predictions = tree_reg.predict(dataset_prepared)\n",
    "\n",
    "# Calcular el error\n",
    "tree_mse = mean_squared_error(dataset['refactoring'], dataset_predictions)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio\n",
    "tree_reg_mse = np.sqrt(tree_mse)\n",
    "print(\"Error cuadrático medio: \", tree_reg_mse)\n",
    "# Raíz del error cuadrático medio\n",
    "rmse = np.sqrt(tree_reg_mse)\n",
    "print(\"Raíz del error cuadrático medio: \", rmse)"
   ],
   "id": "d464815ae05e28b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest Regressor",
   "id": "7f0fc8d2f130cea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Entrenamiento y evaluación de modelos en el conjunto de entrenamiento\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor  # Importar modelo de bosque aleatorio\n",
    "\n",
    "# Seleccionar el modelo\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "# Entrenar el modelo\n",
    "forest_reg.fit(dataset_prepared, dataset['refactoring'])\n",
    "\n",
    "# Predecir en todo el conjunto de entrenamiento\n",
    "dataset_predictions = forest_reg.predict(dataset_prepared)\n",
    "\n",
    "# Calcular el error\n",
    "forest_mse = mean_squared_error(dataset['refactoring'], dataset_predictions)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio\n",
    "forest_reg_mse = np.sqrt(forest_mse)\n",
    "print(\"Error cuadrático medio: \", forest_reg_mse)\n",
    "# Raíz del error cuadrático medio\n",
    "rmse = np.sqrt(forest_reg_mse)\n",
    "print(\"Raíz del error cuadrático medio: \", rmse)"
   ],
   "id": "245af1eef8ba58da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validación cruzada",
   "id": "d85b8beb305eea9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  # Importar validación cruzada\n",
    "\n",
    "# Función para mostrar los resultados\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard deviation: \", scores.std())"
   ],
   "id": "a9e98d9541d8302f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada para el modelo de regresión lineal\n",
    "lin_scores = cross_val_score(lin_reg, dataset_prepared, dataset['refactoring'], scoring='neg_mean_squared_error', cv=10)\n",
    "lin_reg_mse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Regresión lineal:\")\n",
    "display_scores(lin_reg_mse_scores)"
   ],
   "id": "f2c9333082b51c25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada para el modelo de árbol de decisión\n",
    "tree_scores = cross_val_score(tree_reg, dataset_prepared, dataset['refactoring'], scoring='neg_mean_squared_error', cv=10)\n",
    "tree_reg_mse_scores = np.sqrt(-tree_scores)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Árbol de decisión:\")\n",
    "display_scores(tree_reg_mse_scores)"
   ],
   "id": "d95b6b623bca82c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada para el modelo de bosque aleatorio\n",
    "forest_scores = cross_val_score(forest_reg, dataset_prepared, dataset['refactoring'], scoring='neg_mean_squared_error', cv=10)\n",
    "forest_reg_mse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Bosque aleatorio:\")\n",
    "display_scores(forest_reg_mse_scores)"
   ],
   "id": "85c77ad416536d48",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
