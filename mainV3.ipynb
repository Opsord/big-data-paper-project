{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importación de librerías",
   "id": "d56a724eca08670d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Importaciones necesarias\n",
    "\n",
    "# Selección de dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Conjunto de pruebas\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from zlib import crc32\n",
    "\n",
    "# Exploración\n",
    "import seaborn as sns  # Librería para visualización de datos\n",
    "import matplotlib.pyplot as plt  # Importar matplotlib para visualización\n",
    "\n",
    "# Preparación de datos\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Transformación de datos\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Entrenamiento y evaluación de modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Importar clasificadores\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importaciones de métricas\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Validación cruzada\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "id": "7ef6595393524190",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df2a9491",
   "metadata": {},
   "source": [
    "## Selección de dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3c74c3e",
   "metadata": {},
   "source": [
    "# Cargar los datasets\n",
    "df_only_trivial = pd.read_csv('datasets/OnlyTrivial_dt.csv') # Cargar el dataset de casos triviales\n",
    "df_only_non_trivial = pd.read_csv('datasets/OnlyNonTrivial_dt.csv') # Cargar el dataset de casos no triviales\n",
    "\n",
    "# Seleccionar el dataset y crear una copia explícita\n",
    "dataset = df_only_trivial.copy() # Seleccionar el dataset de casos triviales y crear una copia para manipularlo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81f2e3ec",
   "metadata": {},
   "source": "## Información de dataset"
  },
  {
   "cell_type": "code",
   "id": "efff255e",
   "metadata": {},
   "source": [
    "# Mostrar las primeras filas del dataset\n",
    "dataset.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f519e66e",
   "metadata": {},
   "source": [
    "# Mostrar la información del dataset\n",
    "dataset.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1635b75",
   "metadata": {},
   "source": [
    "# Descripción estadística del dataset\n",
    "dataset.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c137e1fd",
   "metadata": {},
   "source": [
    "# Histograma de las características principales\n",
    "principal_metrics = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "# Generar histograma\n",
    "dataset[principal_metrics].hist(bins=50, figsize=(20, 15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6f4b2b3",
   "metadata": {},
   "source": [
    "## Conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "id": "db540242",
   "metadata": {},
   "source": [
    "# Dividir el dataset en un conjunto de entrenamiento y uno de prueba\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mostrar la cantidad de datos en cada conjunto\n",
    "print(\"Largo de conjuntos: \")\n",
    "print(\"Entrenamiento: \", len(train_set))\n",
    "print(\"Prueba: \", len(test_set))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcdcfcf4",
   "metadata": {},
   "source": [
    "# Estabilización de los conjuntos de entrenamiento y prueba\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "# Como el dataset no tiene una columna de identificación, se creará \n",
    "# una columna con el índice de cada fila\n",
    "dataset_with_id = dataset.reset_index()\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "train_set, test_set = split_train_test_by_id(dataset_with_id, 0.2, \"index\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a5cbfc3",
   "metadata": {},
   "source": [
    "## Exploración"
   ]
  },
  {
   "cell_type": "code",
   "id": "525e224f",
   "metadata": {},
   "source": [
    "# Copia de dataset para manipulación\n",
    "exploration_dataset = train_set.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "928061dc",
   "metadata": {},
   "source": [
    "# Escalado de las características principales\n",
    "\n",
    "# Seleccionar las columnas a escalar\n",
    "columns_to_scale = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "\n",
    "# Asegurar que las columnas sean de tipo float64\n",
    "exploration_dataset[columns_to_scale] = exploration_dataset[columns_to_scale].astype('float64')\n",
    "\n",
    "# Crear un pipeline para el escalado\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Aplicar el escalado a las columnas seleccionadas\n",
    "exploration_dataset[columns_to_scale] = pipeline.fit_transform(exploration_dataset[columns_to_scale])\n",
    "\n",
    "# Mapa de calor de correlaciones\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(dataset[columns_to_scale].corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2dfb8a1e90c6dbfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparación de datos",
   "id": "f3a57235d2425a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Limpieza de datos nulos mediante reemplazo por la mediana con SimpleImputer\n",
    "\n",
    "# Crear un SimpleImputer con la estrategia de reemplazo por la mediana\n",
    "# Se ocupa la mediana por ser más robusta a valores atípicos\n",
    "imputer = SimpleImputer(strategy='median') \n",
    "\n",
    "# Seleccionar las columnas numéricas\n",
    "numerical_columns = dataset.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Aplicar el imputer a las columnas numéricas\n",
    "imputer.fit(dataset[numerical_columns])\n",
    "\n",
    "# Transformar el dataset\n",
    "dataset[numerical_columns] = imputer.transform(dataset[numerical_columns])\n",
    "\n",
    "# Verificar si hay valores nulos\n",
    "dataset.isnull().sum()"
   ],
   "id": "8dcf87e435676aba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Paso de variables categóricas a numéricas Parte 1\n",
    "\n",
    "# Seleccionar las columnas categóricas (Solo se debe ocupar la columna 'type')\n",
    "categorical_columns = ['type']\n",
    "\n",
    "# Crear un OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Aplicar el OrdinalEncoder a las columnas categóricas\n",
    "type_encoded = ordinal_encoder.fit_transform(dataset[categorical_columns])\n",
    "\n",
    "# Mostrar las categorías\n",
    "ordinal_encoder.categories_"
   ],
   "id": "67aee8587584d4a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Paso de variables categóricas a numéricas Parte 2\n",
    "\n",
    "# Crear un OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "# Aplicar el OneHotEncoder a las columnas categóricas\n",
    "type_1hot = cat_encoder.fit_transform(dataset[categorical_columns])\n",
    "\n",
    "# Mostrar las categorías\n",
    "type_1hot.toarray()"
   ],
   "id": "a5202e93472c3097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformación de datos",
   "id": "f5fc7b42a93d8c4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Crear un pipeline para la transformación de datos\n",
    "\n",
    "# Definir pipeline para las columnas numéricas\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Seleccionar las columnas numéricas (metricas principales)\n",
    "numerical_columns = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "\n",
    "# Aplicar el pipeline a las columnas numéricas\n",
    "dataset_transformed = num_pipeline.fit_transform(dataset[numerical_columns])\n",
    "\n",
    "# Limpiar valores nulos\n",
    "#dataset_transformed = dataset.dropna(subset=numerical_columns)\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataset_transformed"
   ],
   "id": "9339df0a0e66e0ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combinar transformaciones\n",
    "\n",
    "# Seleccionar las columnas categóricas\n",
    "categorical_columns = ['type']\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numerical_columns = ['cbo', 'cboModified', 'fanin', 'fanout', 'wmc', 'dit', 'noc', 'rfc', 'lcom', 'lcom*']\n",
    "\n",
    "# Crear un ColumnTransformer\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, numerical_columns),\n",
    "    ('cat', OneHotEncoder(), categorical_columns)\n",
    "])\n",
    "\n",
    "# Aplicar el ColumnTransformer al dataset\n",
    "dataset_prepared = full_pipeline.fit_transform(dataset)\n",
    "\n",
    "# Mostrar el resultado\n",
    "dataset_prepared"
   ],
   "id": "ec4f98d9bbe87dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrenamiento y evaluación de modelos en el conjunto de entrenamiento",
   "id": "97b4264c3e7d0c71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funciones de entrenamiento",
   "id": "1cb663e5c6245b02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Entrena un modelo con los datos de entrenamiento.\n",
    "    \"\"\"\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, x_data, y_data, dataset_name=\"Entrenamiento\"):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo y calcula métricas para el conjunto de datos especificado.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x_data)\n",
    "    mse = mean_squared_error(y_data, predictions)\n",
    "    root_mse = np.sqrt(mse)\n",
    "\n",
    "    print(f\"Resultados en {dataset_name}:\")\n",
    "    print(f\"Modelo: {model.__class__.__name__}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {root_mse:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return predictions, mse, root_mse\n",
    "\n",
    "\n",
    "def evaluate_model_with_classification_metrics(model, x_data, y_data, dataset_name=\"Entrenamiento\", classification=False):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo y calcula métricas para el conjunto de datos especificado.\n",
    "    Incluye métricas adicionales si el modelo es de clasificación.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x_data)\n",
    "\n",
    "    if classification:\n",
    "        accuracy = accuracy_score(y_data, predictions)\n",
    "        precision = precision_score(y_data, predictions)\n",
    "        recall = recall_score(y_data, predictions)\n",
    "        f1 = f1_score(y_data, predictions)\n",
    "\n",
    "        print(f\"Resultados en {dataset_name}:\")\n",
    "        print(f\"Modelo: {model.__class__.__name__}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        return predictions, accuracy, precision, recall, f1\n",
    "    else:\n",
    "        mse = mean_squared_error(y_data, predictions)\n",
    "        root_mse = np.sqrt(mse)\n",
    "\n",
    "        print(f\"Resultados en {dataset_name}:\")\n",
    "        print(f\"Modelo: {model.__class__.__name__}\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"RMSE: {root_mse:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        return predictions, mse, root_mse\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test=None, y_test=None):\n",
    "    # Entrenar el modelo\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predecir\n",
    "    predictions = model.predict(x_train)  # En conjunto de entrenamiento\n",
    "    if x_test is not None:\n",
    "        test_predictions = model.predict(x_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    root_mse = np.sqrt(mse)\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(f\"Modelo: {model.__class__.__name__}\")\n",
    "    print(f\"Error cuadrático medio (MSE): {mse:.4f}\")\n",
    "    print(f\"Raíz del error cuadrático medio (RMSE): {root_mse:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return predictions, mse, root_mse"
   ],
   "id": "8100e7d3fee02a41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "79b9ce0fcaf2178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Regresión Lineal: Entrenamiento\n",
    "\n",
    "# Instanciar el modelo\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "lin_reg = train_model(lin_reg, dataset_prepared, dataset['refactoring'])\n"
   ],
   "id": "77c6ef547dc3ef8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Regresión Lineal: Evaluación\n",
    "# Evaluar en conjunto de entrenamiento\n",
    "lin_train_predictions, lin_train_mse, lin_train_rmse = evaluate_model(lin_reg, dataset_prepared, dataset['refactoring'], dataset_name=\"Entrenamiento\")\n"
   ],
   "id": "cb24369456c80be9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression",
   "id": "bd7894c00c1838ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Regresión Logística: Entrenamiento\n",
    "\n",
    "# Instanciar el modelo\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "log_reg = train_model(log_reg, dataset_prepared, dataset['refactoring'])"
   ],
   "id": "4ed3ece7100c80a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Regresión Logística: Evaluación\n",
    "# Evaluar en conjunto de entrenamiento\n",
    "log_train_predictions, log_train_accuracy, log_train_precision, log_train_recall, log_train_f1 = evaluate_model_with_classification_metrics(log_reg, dataset_prepared, dataset['refactoring'], dataset_name=\"Entrenamiento\", classification=True)"
   ],
   "id": "57e19766d6db3508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree Regressor",
   "id": "205b37093f3732bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Árbol de Decisión: Entrenamiento\n",
    "\n",
    "# Instanciar el modelo\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "\n",
    "# Entrenar el modelo\n",
    "dt_reg = train_model(dt_reg, dataset_prepared, dataset['refactoring'])"
   ],
   "id": "d464815ae05e28b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Árbol de Decisión: Evaluación\n",
    "# Evaluar en conjunto de entrenamiento\n",
    "dt_train_predictions, dt_train_mse, dt_train_rmse = evaluate_model(dt_reg, dataset_prepared, dataset['refactoring'], dataset_name=\"Entrenamiento\")\n"
   ],
   "id": "4c3c3c3646a3c279",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree Classifier",
   "id": "3fda1f039731c23a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Árbol de Decisión: Entrenamiento\n",
    "\n",
    "# Instanciar el modelo\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Entrenar el modelo\n",
    "dt_clf = train_model(dt_clf, dataset_prepared, dataset['refactoring'])"
   ],
   "id": "eafcef86a000b18f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Árbol de Decisión: Evaluación\n",
    "# Evaluar en conjunto de entrenamiento\n",
    "dt_train_predictions, dt_train_accuracy, dt_train_precision, dt_train_recall, dt_train_f1 = evaluate_model_with_classification_metrics(dt_clf, dataset_prepared, dataset['refactoring'], dataset_name=\"Entrenamiento\", classification=True)\n"
   ],
   "id": "b7d65dc4bd29c2d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest Regressor",
   "id": "7f0fc8d2f130cea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bosque Aleatorio: Entrenamiento\n",
    "\n",
    "# Instanciar el modelo\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_reg = train_model(rf_reg, dataset_prepared, dataset['refactoring'])"
   ],
   "id": "245af1eef8ba58da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bosque Aleatorio: Evaluación\n",
    "# Evaluar en conjunto de entrenamiento\n",
    "rf_train_predictions, rf_train_mse, rf_train_rmse = evaluate_model(rf_reg, dataset_prepared, dataset['refactoring'], dataset_name=\"Entrenamiento\")\n"
   ],
   "id": "57eaafccc7b4ca38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest Classifier",
   "id": "7ba9fb62e9839f1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bosque Aleatorio: Entrenamiento\n",
    "\n",
    "# Instanciar el modelo\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_clf = train_model(rf_clf, dataset_prepared, dataset['refactoring'])"
   ],
   "id": "52287fea4166001b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bosque Aleatorio: Evaluación\n",
    "# Evaluar en conjunto de entrenamiento\n",
    "rf_train_predictions, rf_train_accuracy, rf_train_precision, rf_train_recall, rf_train_f1 = evaluate_model_with_classification_metrics(rf_clf, dataset_prepared, dataset['refactoring'], dataset_name=\"Entrenamiento\", classification=True)"
   ],
   "id": "6785b6af4cf0c53f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Validación cruzada",
   "id": "d85b8beb305eea9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada\n",
    "\n",
    "global_cv = 5\n",
    "\n",
    "# Función para mostrar los resultados\n",
    "def display_scores(scores, metric_name):\n",
    "    print(f\"{metric_name}:\", scores)"
   ],
   "id": "a9e98d9541d8302f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regresión Logística",
   "id": "5cf8618b60afb17a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada para el modelo de regresión logística\n",
    "accuracy_scores = cross_val_score(log_reg, dataset_prepared, dataset['refactoring'], scoring='accuracy', cv=global_cv)\n",
    "precision_scores = cross_val_score(log_reg, dataset_prepared, dataset['refactoring'], scoring='precision', cv=global_cv)\n",
    "recall_scores = cross_val_score(log_reg, dataset_prepared, dataset['refactoring'], scoring='recall', cv=global_cv)\n",
    "f1_scores = cross_val_score(log_reg, dataset_prepared, dataset['refactoring'], scoring='f1', cv=global_cv)"
   ],
   "id": "678b9fbbc6a86007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Regresión Logística:\")\n",
    "print(\"Accuracy:\", accuracy_scores)\n",
    "print(\"Precision:\", precision_scores)\n",
    "print(\"Recall:\", recall_scores)\n",
    "print(\"F1 Score:\", f1_scores)"
   ],
   "id": "f2c9333082b51c25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree Regressor",
   "id": "3afc679767b651ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validación cruzada para el modelo de árbol de decisión\n",
    "accuracy_scores = cross_val_score(dt_clf, dataset_prepared, dataset['refactoring'], scoring='accuracy', cv=global_cv)\n",
    "precision_scores = cross_val_score(dt_clf, dataset_prepared, dataset['refactoring'], scoring='precision', cv=global_cv)\n",
    "recall_scores = cross_val_score(dt_clf, dataset_prepared, dataset['refactoring'], scoring='recall', cv=global_cv)\n",
    "f1_scores = cross_val_score(dt_clf, dataset_prepared, dataset['refactoring'], scoring='f1', cv=global_cv)"
   ],
   "id": "3f16d1e91389913a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Árbol de decisión:\")\n",
    "print(\"Accuracy:\", accuracy_scores)\n",
    "print(\"Precision:\", precision_scores)\n",
    "print(\"Recall:\", recall_scores)\n",
    "print(\"F1 Score:\", f1_scores)"
   ],
   "id": "481290c0067e2304",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest Regressor",
   "id": "70f8f784f18fdbcb"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    " # Validación cruzada para el modelo de random forest\n",
    "accuracy_scores = cross_val_score(rf_clf, dataset_prepared, dataset['refactoring'], scoring='accuracy', cv=global_cv)\n",
    "precision_scores = cross_val_score(rf_clf, dataset_prepared, dataset['refactoring'], scoring='precision', cv=global_cv)\n",
    "recall_scores = cross_val_score(rf_clf, dataset_prepared, dataset['refactoring'], scoring='recall', cv=global_cv)\n",
    "f1_scores = cross_val_score(rf_clf, dataset_prepared, dataset['refactoring'], scoring='f1', cv=global_cv)"
   ],
   "id": "f2ac2628015c9918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Mostrar los resultados\n",
    "print(\"Random Forest:\")\n",
    "print(\"Accuracy:\", accuracy_scores)\n",
    "print(\"Precision:\", precision_scores)\n",
    "print(\"Recall:\", recall_scores)\n",
    "print(\"F1 Score:\", f1_scores)"
   ],
   "id": "d73b60aba39cbe46",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
